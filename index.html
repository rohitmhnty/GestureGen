<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Video Analysis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2501.18898"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/andypinxinliu/GestureLSM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="./static/images/gesturelsm-teaser.jpg"/>
      <p>
        <b>GestureLSM</b>. We present Gesture Latent Shortcut Model, a method that generates full-body human gestures from speech with high quality and real-time speed. It explicitly models the body regions interactions, e.g., the interactions between body and hands, to achieve coherent and smooth overall gesture motions.  Besides, it is also capable of real-time generation based on shortcut sampling.
      </p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating full-body human gestures based on speech signals remains challenges on quality and speed. Existing approaches model different body regions such as body, legs and hands separately, which fail to capture the spatial interactions between them and result in unnatural and disjointed movements. Additionally, their autoregressive/diffusion-based pipelines show slow generation speed due to dozens of inference steps. To address these two challenges, we propose <b>GestureLSM</b>, a flow-matching-based approach for Co-Speech Gesture Generation with spatial-temporal modeling. Our method i) explicitly model the interaction of tokenized body regions through spatial and temporal attention, for generating coherent full-body gestures. ii) introduce the flow matching to enable more efficient sampling by explicitly modeling the latent velocity space. To overcome the suboptimal performance of flow matching baseline, we propose latent shortcut learning and beta distribution time stamp sampling during training to enhance gesture synthesis quality and accelerate inference. Combining the spatial-temporal modeling and improved flow matching-based framework, GestureLSM achieves state-of-the-art performance on BEAT2 while significantly reducing inference time compared to existing methods, highlighting its potential for enhancing digital humans and embodied agents in real-world applications.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3" style="text-align: center;">Method</h2>
    <div class="content has-text-centered">
        <img src="./static/images/gesturelsm-pipeline.jpg"/>
      <p>(1) GestureLSM generate full-body gestures from speech and text scripts. From left to right, the concatenated audio and text features are fused into gesture features via cross-attention. The condition fused gesture features are adopted to decode gesture latents with our proposed spatial-temporal decoder. The optimization objective is based on the flow matching. (2) The gesture latents are from pretrained RVQ (Residual Vector Quantization) models. (3) The details of spatial-temporal attention, it integrates with position encoding to learn the interaction of body regions.</p>
        
    </div>
  </div>
</section>


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Comparison on BEAT2</h2>
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/output-1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/output-2.mp4"
            type="video/mp4">
          </video>
        </div>
        
      <!-- </div> -->
      <h2 class="content has-text-centered">
        GestureLSM achieves more natural gesture motions conditioned on speech audio, benefiting from the spatial-temporal modeling based on spatial and temporal attentions. The generated gestures are coherent and smooth,
        while other works always present temporal jittering, abnormal body parts movements, and disjointed gestures.
      </h2>
    </div>
  </div>
</section>
<!-- End video carousel -->





<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Additional Results</h2>

        <div class="content">
          <div class="columns is-centered">
            <!-- Left Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex1.mp4" type="video/mp4">
              </video>
            </div>
            
            <!-- Left Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex2.mp4" type="video/mp4">
              </video>
            </div>
          </div>

          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex4.mp4" type="video/mp4">
              </video>
            </div>
            
          </div>

          <div class="columns is-centered">
            <!-- Left Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex5.mp4" type="video/mp4">
              </video>
            </div>
            
            <!-- Middle Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex6.mp4" type="video/mp4">
              </video>
            </div>
          </div>


          <div class="columns is-centered">
            <!-- Left Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex7.mp4" type="video/mp4">
              </video>
            </div>
            
            <!-- Middle Video -->
            <div class="column is-half has-text-centered">
              <video poster="" autoplay controls muted loop height="100%">
                <source src="./static/videos/ex8.mp4" type="video/mp4">
              </video>
            </div>
          </div>



        </div>
        <h2 class="content has-text-centered">
          GestureLSM can generate various gestures with different body regions and motions, showcasing its potential for various applications in the development of digital humans and embodied agents.
    </div>
  </div>
</section>
<!-- End video carousel -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code></code>@misc{liu2025gesturelsmlatentshortcutbased,
      title={GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling}, 
      author={Pinxin Liu and Luchuan Song and Junhua Huang and Chenliang Xu},
      year={2025},
      eprint={2501.18898},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.18898}, 
}
    </code></pre>
  </div>
</section>

<footer class="footer" style="padding-top: 6px; padding-bottom: 6px;">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Our website template is a modified version of <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. Thanks to the authors' contribution.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>





</body>
</html>